plot(hclust2)
# veamos como queda el corte con 10 clusters
clusters_hier2 = factor(cutree(hclust2, k = 10))
ggplot(mz_lc) +
geom_sf(aes(fill = clusters_hier2))
# Cargar Librerias
pacman::p_load(tidyverse, sf, MASS, gstat, raster,
spdep, spatialreg, patchwork)
# manzanas las condes
mz_lc = read_rds("data/MBHT_LC.rds")
# generamos lista de vecinos
nb = poly2nb(mz_lc, queen=TRUE)
# generamos pesos a partir de los vecinos
lw = nb2listw(nb, style="W", zero.policy=TRUE)
plot(lw, coords = st_coordinates(st_centroid(mz_lc)), col='red')
# buffer
poly_buff =
mz_lc |>
st_buffer(dist=50) |>
st_cast("MULTIPOLYGON")
buff_nb = mat2listw(st_overlaps(poly_buff, sparse=FALSE))
plot(buff_nb, coords = st_coordinates(st_centroid(mz_lc)), col='red')
# knn
nvec = 12
knn_nb = spdep::nb2listw(neighbours = spdep::knn2nb(
knn = spdep::knearneigh( x = st_centroid(mz_lc), k = nvec, longlat = F)),
style = "W")
plot(knn_nb, coords = st_coordinates(st_centroid(mz_lc)), col='red')
# radio
radius = 500
# calcula matriz de distancias
dist_mat =
st_distance(st_centroid(mz_lc), st_centroid(mz_lc))
# calcula el inverso y asigna 0 en la diagonal
distancias.inv = 1/dist_mat
diag(distancias.inv) = 0
# asigna 0 si distancia es mayor al radio
distancias.inv[as.numeric(dist_mat) > radius] = 0
# matriz de pesos
sp_w = matrix(as.numeric(distancias.inv), nrow =  nrow(distancias.inv))
# lista de pesos
rad_nb = mat2listw(sp_w)
plot(rad_nb, coords = st_coordinates(st_centroid(mz_lc)), col='red')
# Cargar Librerias
pacman::p_load(tidyverse, sf, MASS, gstat, raster,
spdep, spatialreg, patchwork)
# manzanas las condes
mz_lc = read_rds("data/MBHT_LC.rds")
# verificamos proyeccion
st_crs(mz_lc)
# visualizamos
ggplot() +
geom_sf(data = mz_lc, aes(fill=ibt))
# exploramos los valores de ingresos
mz_lc$ibt
hist(mz_lc$ibt, main=NULL)
boxplot(mz_lc$ibt, horizontal = TRUE)
mz_lc$ibt |> summary()
# manzanas en version puntos
mz_point = mz_lc |>
st_centroid()
formMod = ibt ~ 1
variog_empirico = variogram(formMod, mz_point, cutoff=5000)
variog_teorico = fit.variogram(variog_empirico,
model = vgm(model  = "Sph", nugget = 0.48))
ggplot() + aes(dist, gamma) +
geom_point(data=variog_empirico) +
geom_line(data=variogramLine(variog_teorico, maxdist = max(5000)))
nvec = 12
knn_nb = spdep::nb2listw(neighbours = spdep::knn2nb(
knn = spdep::knearneigh( x = st_centroid(mz_lc), k = nvec, longlat = F)),
style = "W")
# calculamos el indice global de moran
I = moran(mz_lc$ibt, knn_nb, length(knn_nb), Szero(knn_nb))
I
# calculamos el pvalue del indice
moran.test(mz_lc$ibt, knn_nb, alternative="greater")
lmoran = localmoran(mz_lc$ibt, knn_nb) |> as.data.frame()
# generamos lo cuadrantes de moran
matrix = data.frame(value = ifelse(mz_lc$ibt > mean(mz_lc$ibt), "H", "L"),
correlation = ifelse(lmoran$Ii > mean(lmoran$Ii),"H","L"),
significance = lmoran$`Pr(z != E(Ii))`) |>
mutate(cuadrant = ifelse(significance < 0.1,paste0(value,correlation),NA))
# traspasamos variable a objeto original
mz_lc$cuadrant = matrix$cuadrant
ggplot() +
geom_sf(data=mz_lc, aes(fill=cuadrant))
# Cargar Librerias
pacman::p_load(tidyverse, sf, MASS, gstat, raster,
spdep, spatialreg, patchwork)
# manzanas las condes
mz_lc = read_rds("data/MBHT_LC.rds")
View(mz_lc)
? poly2nb
? nb2listw
# generamos lista de vecinos
nb = poly2nb(mz_lc, queen=TRUE)
# generamos pesos a partir de los vecinos
lw = nb2listw(nb, style="W", zero.policy=TRUE)
plot(lw, coords = st_coordinates(st_centroid(mz_lc)), col='red')
mapview::mapview(mz_lc)
# buffer
poly_buff =
mz_lc |>
st_buffer(dist=50) |>
st_cast("MULTIPOLYGON")
mapview::mapview(poly_buff)
st_overlaps(poly_buff, sparse=FALSE)
buff_nb = mat2listw(st_overlaps(poly_buff, sparse=FALSE))
plot(buff_nb, coords = st_coordinates(st_centroid(mz_lc)), col='red')
# knn
nvec = 12
knn_nb = spdep::nb2listw(neighbours = spdep::knn2nb(
knn = spdep::knearneigh( x = st_centroid(mz_lc), k = nvec, longlat = F)),
style = "W")
plot(knn_nb, coords = st_coordinates(st_centroid(mz_lc)), col='red')
# radio
radius = 500
# calcula matriz de distancias
dist_mat =
st_distance(st_centroid(mz_lc), st_centroid(mz_lc))
# calcula el inverso y asigna 0 en la diagonal
distancias.inv = 1/dist_mat
diag(distancias.inv) = 0
# asigna 0 si distancia es mayor al radio
distancias.inv[as.numeric(dist_mat) > radius] = 0
# matriz de pesos
sp_w = matrix(as.numeric(distancias.inv), nrow =  nrow(distancias.inv))
# lista de pesos
rad_nb = mat2listw(sp_w)
plot(rad_nb, coords = st_coordinates(st_centroid(mz_lc)), col='red')
gc()
# Cargar Librerias
pacman::p_load(tidyverse, sf, MASS, gstat, raster,
spdep, spatialreg, patchwork)
# manzanas las condes
mz_lc = read_rds("data/MBHT_LC.rds")
# verificamos proyeccion
st_crs(mz_lc)
# visualizamos
ggplot() +
geom_sf(data = mz_lc, aes(fill=ibt))
# visualizamos
ggplot() +
geom_sf(data = mz_lc, aes(fill=ibt)) +
scale_fill_viridis_c()
# exploramos los valores de ingresos
mz_lc$ibt
hist(mz_lc$ibt, main=NULL)
boxplot(mz_lc$ibt, horizontal = TRUE)
mz_lc$ibt |> summary()
# manzanas en version puntos
mz_point = mz_lc |>
st_centroid()
formMod = ibt ~ 1
? variogram
variog_empirico = variogram(formMod, mz_point, cutoff=5000)
View(variog_empirico)
? fit.variogram
variog_teorico = fit.variogram(variog_empirico,
model = vgm(model  = "Sph", nugget = 0.48))
ggplot() + aes(dist, gamma) +
geom_point(data=variog_empirico) +
geom_line(data=variogramLine(variog_teorico, maxdist = max(5000)))
1661*1661
nvec = 12
knn_nb = spdep::nb2listw(neighbours = spdep::knn2nb(
knn = spdep::knearneigh( x = st_centroid(mz_lc), k = nvec, longlat = F)),
style = "W")
? moran
? Szero
# calculamos el indice global de moran
I = moran(mz_lc$ibt, knn_nb, length(knn_nb), Szero(knn_nb))
I
# calculamos el pvalue del indice
moran.test(mz_lc$ibt, knn_nb, alternative="greater")
? localmoran
lmoran = localmoran(mz_lc$ibt, knn_nb) |> as.data.frame()
View(lmoran)
mean(lmoran$Ii)
# generamos lo cuadrantes de moran
matrix = data.frame(value = ifelse(mz_lc$ibt > mean(mz_lc$ibt), "H", "L"),
correlation = ifelse(lmoran$Ii > mean(lmoran$Ii),"H","L"),
significance = lmoran$`Pr(z != E(Ii))`) |>
mutate(cuadrant = ifelse(significance < 0.1,paste0(value,correlation),NA))
View(matrix)
# traspasamos variable a objeto original
mz_lc$cuadrant = matrix$cuadrant
ggplot() +
geom_sf(data=mz_lc, aes(fill=cuadrant))
# invocamos las librerias
pacman::p_load(sf, tidyverse, spdep)
options(scipen = 999)
# cargamos los datos
mz_lc = read_rds("data/MBHT_LC.rds") |>
drop_na()
# extraemos las variables numericas que vamos a estudiar
lc_vars = mz_lc |>
dplyr::select(ibt:E65YMAS) |>
drop_na() |>
st_drop_geometry() |>
mutate(across(where(is.numeric), ~ as.numeric(scale(.))))
# exploramos la distribucion de las variables
hist(lc_vars$dim_acc)
hist(lc_vars$dim_amb)
hist(lc_vars$dim_seg)
hist(lc_vars$dim_soc)
# usamos el metodo mas sencillo, kmeans, para agrupar los condados en 10 clusters segun las variables
clusters_k = kmeans(lc_vars, 10)
# usamos el metodo mas sencillo, kmeans, para agrupar los condados en 10 clusters segun las variables
clusters_k = kmeans(lc_vars, 10)
# creamos la variable cluster en el conjunto nc
mz_lc$cluster_kmeans = as.factor(clusters_k$cluster)
# visualizamos
ggplot(mz_lc) +
geom_sf(aes(fill = cluster_kmeans))
clusters_k$betweenss / mean(dist(lc_vars))
# calculamos distancia de atributos
dist_attr = dist(lc_vars)
1453*1453
# generamos modelo jerarquico
hclust = hclust(dist_attr)
plot(hclust)
dist_attr |> summary()
# cortamos modelo en 10 clusters
clusters_hier = factor(cutree(hclust, k = 10))
ggplot(mz_lc) +
geom_sf(aes(fill = clusters_hier)) +
scale_fill_viridis_d()
? hclust
# generamos modelo jerarquico
hclust = hclust(dist_attr, method = "single")
plot(hclust)
# cortamos modelo en 10 clusters
clusters_hier = factor(cutree(hclust, k = 10))
ggplot(mz_lc) +
geom_sf(aes(fill = clusters_hier)) +
scale_fill_viridis_d()
matriz_vecindad  = spdep::nb2listw(neighbours = spdep::knn2nb(
knn = spdep::knearneigh( x = st_centroid(mz_lc), k = 8, longlat = F)),
style = "W")
# viene como una lista, asi que la transformamos en una matriz
matriz_vec = map(1:nrow(mz_lc), function(i) as.numeric(1:nrow(mz_lc) %in% matriz_vecindad$neighbours[[i]])) |>
unlist() |>
matrix(nrow=nrow(mz_lc))
# la matriz de atributos tambien viene como un objeto de distancia, la pasamos a matriz
matriz_atr = dist_attr |> as.matrix()
# calculamos la matriz de vecindades
matriz_vecindad  = spdep::nb2listw(neighbours = spdep::knn2nb(
knn = spdep::knearneigh( x = st_centroid(mz_lc), k = 8, longlat = F)),
style = "W")
# viene como una lista, asi que la transformamos en una matriz
matriz_vec = map(1:nrow(mz_lc), function(i) as.numeric(1:nrow(mz_lc) %in% matriz_vecindad$neighbours[[i]])) |>
unlist() |>
matrix(nrow=nrow(mz_lc))
# la matriz de atributos tambien viene como un objeto de distancia, la pasamos a matriz
matriz_atr = dist_attr |> as.matrix()
# ahora construimos una matriz de vecindad-atributo
# donde la matriz de vecindad es 0 (no vecino), le asignamos un valor muy grande (10000), de lo contrario,
# mantiene el valor de distanci a de atributos
matriz_atr_vec = (1-matriz_vec)*10000 + matriz_vec*matriz_atr
# pasamos la matriz a objeto distancia (lo que recibe el hclust)
dist_atr_vec = matriz_atr_vec |> as.dist()
# ejecutamos el hclust con esta matriz de vecindad-atributo
hclust2 = hclust(dist_atr_vec, method= "average")
plot(hclust2)
# veamos como queda el corte con 10 clusters
clusters_hier2 = factor(cutree(hclust2, k = 10))
ggplot(mz_lc) +
geom_sf(aes(fill = clusters_hier2))
# Cargar Librerias
library(tidyverse)
library(sf)
library(MASS)
library(gstat)
library(raster)
library(spdep)
library(spatialreg)
library(patchwork)
# ***************************
# Cargar y ordenar datos ----
# manzanas las condes
mz_lc = read_rds("data/MBHT_LC.rds") %>%
filter(PERSONAS > 0)
# Datos de delitos
violencia = read_rds("data/casos_violencia.rds")
# verificamos proyeccion
st_crs(violencia)
# Cargar datos censales de nivel educativo en Las Condes a nivel de personas
censo_lc = readRDS("data/censo_lc.rds") %>%
mutate(ID_MANZ = as.character(IDMZ)) %>%
dplyr::select(-IDMZ)
# Calcular Nivel Educacional de jefes de hogar por manzana
nived = censo_lc %>%
filter(DSOST==1) %>%  # Filtar sostenedores
group_by(ID_MANZ) %>%
summarise(EDUC = mean(EDUC))
# Cargar Poligonos de Manzanas de Las Condes (Censo 2012)
# acoplar con datos de nivel educacional a manzanas
mz_lc = mz_lc %>%
left_join(nived, by = "ID_MANZ") %>%
mutate(area = st_area(.)/10000,
EDUC = ifelse(is.na(EDUC),0,EDUC),
densidad = PERSONAS/area,
violencia = lengths(st_intersects(geometry, violencia)))
# visualizamos
ggplot() +
geom_sf(data = mz_lc) +
geom_sf(data = violencia)
# modelo de regresion convencional
modviol = lm(violencia ~ log(densidad) + EDUC, data = mz_point)
summary(modviol)
## Crear matriz de pesos espaciales
nb = nb2listw(neighbours = knn2nb(
knn = knearneigh(x = mz_point, k = 4)),
style = "W")
# manzanas en version puntos
mz_point = mz_lc %>%
st_centroid()
# modelo de regresion convencional
modviol = lm(violencia ~ log(densidad) + EDUC, data = mz_point)
summary(modviol)
## Crear matriz de pesos espaciales
nb = nb2listw(neighbours = knn2nb(
knn = knearneigh(x = mz_point, k = 4)),
style = "W")
I = moran(modviol$residuals, nb, length(nb), Szero(nb))
moran.test(modviol$residuals, nb, alternative="greater")
summary(mz_point)
#Error espacial
fit.errdurb = errorsarlm(violencia ~ log(densidad) + EDUC, data = mz_point,
listw = nb, etype="error", method="eigen")
summary(fit.errdurb)
moran.test(fit.errdurb$residuals, nb) ## Test Moran residuos
#Lag espacial
fit.durb = lagsarlm(violencia ~ log(densidad) + EDUC, data = mz_point,
listw = nb ,type="lag",method="eigen")
summary(fit.durb)
moran.test(fit.durb$residuals, nb)
#Error y Lag espacial
fit.sac = sacsarlm(violencia ~ log(densidad) + EDUC, data = mz_point,
listw=nb, type="sac", method="eigen")
summary(fit.sac)
moran.test(fit.sac$residuals, nb)
mz_lc =
mz_lc %>%
mutate(reg_lin = predict(modviol),
errsar = fitted(fit.errdurb),
lagsar = fitted(fit.durb),
sacsar = fitted(fit.sac))
p1 = ggplot(data=mz_lc) +
geom_sf(aes(fill=reg_lin)) +
scale_fill_viridis_c()
p2 = ggplot(data=mz_lc) +
geom_sf(aes(fill=errsar)) +
scale_fill_viridis_c()
p3 = ggplot(data=mz_lc) +
geom_sf(aes(fill=lagsar)) +
scale_fill_viridis_c()
p4 = ggplot(data=mz_lc) +
geom_sf(aes(fill=sacsar)) +
scale_fill_viridis_c()
(p1 + p2) / (p3 + p4)
gc()
library(tidygeocoder)
library(sf)
library(mapview)
library(tidyverse)
library(osmdata)
library(igraph)
library(nngeo)
library(sfnetworks)
# leemos poligonos de Las Condes
poligonos <- read_rds("data/MBHT_LC.rds")
LasCondes <- read_sf("data/shapefile/LasCondes.shp")
plot(LasCondes)
# leemos direcciones
direcciones <- read_csv("data/direcciones.csv")
#exploramos listado
direcciones
# leemos direcciones
direcciones <- read_csv("data/direcciones.csv")[1:10]
# leemos direcciones
direcciones <- read_csv("data/direcciones.csv")
#exploramos listado
direcciones = direcciones[1:10]
#exploramos listado
direcciones = direcciones[1:10,]
# intentamos agregando el nombre de Chile tambien
p3 <- geo(paste0(direcciones$DIRECCION," Las Condes, Chile"), method="arcgis")
# generamos objeto espacial con la misma CRS que el objeto base
p3_sf <- p3 %>%
st_as_sf(coords = c("long", "lat"), crs = 4326) %>%
st_transform(st_crs(poligonos))
# visualizamos
p3_sf %>% mapview(legend = FALSE)
# identificamos el bbox de las condes
LC_bbox <- getbb("Las Condes, Santiago, Chile")
available_tags("highway")
# extraigo las calles principales y sus nodos desde OSM
LC_hway <- opq(LC_bbox) %>% # identifico bbox
add_osm_feature( # agrego atributo del listado anterior
key = "highway",
#    value = c("motorway", "primary", "residential", "secondary", "terciary", "living_street") # se pueden agregar despues secondary terciary available
) %>%
osmdata_sf() %>% # transformo en sf
pluck("osm_lines") %>% # preservo solo elementos de osm_lines
st_transform(crs=st_crs(poligonos))  # dejo en misma proyeccion que objeto base
mapview(LC_hway)
mapview(LasCondes)
# extramos solo las calles que intersectan con las condes
calles_LC <-
LC_hway %>% # tomamos toda la base
filter(LC_hway %>%  #fitramos cuando hay interseccion entre las calles y
st_intersects(LasCondes %>% # el poligono del perimetro de las condes
st_buffer(dist = 15)) %>%  # con un margen de 15 metros
summary() %>% # el resumen de intersect devuelve 1 si hay interseccion 0 eoc
.[,1] %>% # este valor de 1 viene en la primera columna
as.numeric() == 1) %>% # verifico si el resultado de esta operacion es 1
drop_na(name) %>%
filter(surface %in% c("asphalt", "concrete", "paved", "paving_stones", "cobblestone", "cobblestone:flattened"))
# visualizamos recorridos de transporte publico
mapview(calles_LC)
# generamos red de calles
net <- as_sfnetwork(calles_LC, directed = FALSE)
plot(net)
shortest_paths(net, 1, 9, algorithm = "dijkstra")
path <- shortest_paths(net, 1, 9, algorithm = "dijkstra")
# calculamos una ruta en particular, del 1 al 9
path <- shortest_paths(net, 1, 9, algorithm = "dijkstra")$vpath[[1]]
# extraemos del objeto net los puntos del camino mas corto
path_net <- st_geometry(net)[path %>% as.numeric()] %>%
st_as_sf("POINT")
# agregamos puntos al mapa, de color rojo
plot(path_net, add=TRUE, col="red", lwd  = 8)
# identificamos vecinos mas cercanos a entidades espaciales y preservamos los casos unicos
nn_direcciones <- st_nn(p3_sf, net)
nn_poligonos <- st_nn(st_centroid(poligonos), net)
nn_dir_unicos <- unique(nn_direcciones)
nn_poligonos <- st_nn(st_centroid(poligonos), net)
nn_pol_unicos <- unique(nn_poligonos)
# calculamos la ruta de todos con todos
distancia_red <- shortest_paths(net, from = nn_dir_unicos , to = nn_pol_unicos, output = "epath")
View(distancia_red)
# podemos calcular la distancia de cada poligono a cada junta de vecinos
distancia_euclideana <- st_distance(poligonos, p3_sf)
# preservamos la menor distancia para asociar una manzana a una JJVV
# generamos indicador de accesibilidad a jjvv
poligonos <-
poligonos %>%
mutate(accesibilidad = apply(distancia_euclideana, 1, function(x) min(x)))
# visualizamos
ggplot() +
geom_sf(data=poligonos, aes(fill=accesibilidad))+
geom_sf(data = p3_sf, size = 2, col = "white") +
scale_fill_viridis_c(direction = -1)
nn_dir_unicos
# calculamos la ruta de todos con todos
distancia_red <- shortest_paths(net, from = nn_dir_unicos[1] , to = nn_pol_unicos, output = "epath")
# podemos calcular la distancia de cada poligono a cada junta de vecinos
distancia_euclideana <- st_distance(poligonos, p3_sf[1])
# preservamos la menor distancia para asociar una manzana a una JJVV
# generamos indicador de accesibilidad a jjvv
poligonos <-
poligonos %>%
mutate(accesibilidad = apply(distancia_euclideana, 1, function(x) min(x)))
# visualizamos
ggplot() +
geom_sf(data=poligonos, aes(fill=accesibilidad))+
geom_sf(data = p3_sf, size = 2, col = "white") +
scale_fill_viridis_c(direction = -1)
# podemos calcular la distancia de cada poligono a cada junta de vecinos
distancia_euclideana <- st_distance(poligonos, p3_sf[1,])
# preservamos la menor distancia para asociar una manzana a una JJVV
# generamos indicador de accesibilidad a jjvv
poligonos <-
poligonos %>%
mutate(accesibilidad = apply(distancia_euclideana, 1, function(x) min(x)))
# visualizamos
ggplot() +
geom_sf(data=poligonos, aes(fill=accesibilidad))+
geom_sf(data = p3_sf, size = 2, col = "white") +
scale_fill_viridis_c(direction = -1)
# visualizamos
ggplot() +
geom_sf(data=poligonos, aes(fill=accesibilidad))+
geom_sf(data = p3_sf[1,], size = 2, col = "white") +
scale_fill_viridis_c(direction = -1)
# podemos calcular la distancia de cada poligono a cada junta de vecinos
distancia_euclideana <- st_distance(poligonos, p3_sf[2,])
# preservamos la menor distancia para asociar una manzana a una JJVV
# generamos indicador de accesibilidad a jjvv
poligonos <-
poligonos %>%
mutate(accesibilidad = apply(distancia_euclideana, 1, function(x) min(x)))
# visualizamos
ggplot() +
geom_sf(data=poligonos, aes(fill=accesibilidad))+
geom_sf(data = p3_sf[2,], size = 2, col = "white") +
scale_fill_viridis_c(direction = -1)
# podemos calcular la distancia de cada poligono a cada junta de vecinos
distancia_euclideana <- st_distance(poligonos, p3_sf[3,])
# preservamos la menor distancia para asociar una manzana a una JJVV
# generamos indicador de accesibilidad a jjvv
poligonos <-
poligonos %>%
mutate(accesibilidad = apply(distancia_euclideana, 1, function(x) min(x)))
# visualizamos
ggplot() +
geom_sf(data=poligonos, aes(fill=accesibilidad))+
geom_sf(data = p3_sf[3,], size = 2, col = "white") +
scale_fill_viridis_c(direction = -1)
